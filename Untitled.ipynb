{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 17.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# 目标编码\n",
    "def kfold_mean(df_train, df_test, target, target_mean_list):\n",
    "    folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    mean_of_target = df_train[target].mean()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in tqdm(\n",
    "            enumerate(folds.split(df_train, y=df_train['label']))):\n",
    "        tr_x = df_train.iloc[trn_idx, :]\n",
    "        vl_x = df_train.iloc[val_idx, :]\n",
    "\n",
    "        for col in target_mean_list:\n",
    "            df_train.loc[vl_x.index, f'{col}_target_enc'] = vl_x[col].map(\n",
    "                tr_x.groupby(col)[target].mean())\n",
    "\n",
    "    for col in target_mean_list:\n",
    "        df_train[f'{col}_target_enc'].fillna(mean_of_target, inplace=True)\n",
    "\n",
    "        df_test[f'{col}_target_enc'] = df_test[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "\n",
    "        df_test[f'{col}_target_enc'].fillna(mean_of_target, inplace=True)\n",
    "    return pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "feature_list =  ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT'\n",
    "                   ]\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "data = kfold_mean(data[~data['label'].isna()], data[data['label'].isna()],\n",
    "                  'label',\n",
    "                  feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 频数统计\n",
    "cat_col = ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT']\n",
    "for col in cat_col:\n",
    "    data[col + '_COUNT'] = data[col].map(data[col].value_counts())\n",
    "    col_idx = data[col].value_counts()\n",
    "    for idx in col_idx[col_idx < 10].index:\n",
    "        data[col] = data[col].replace(idx, -1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偏离值特征\n",
    "group_list = ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT']\n",
    "num_feature_list = ['GRYJCE', 'DKFFE', 'DKLL', 'DKYE', 'GRJCJS', 'GRZHSNJZYE', 'GRZHDNGJYE']                   \n",
    "for group in group_list:\n",
    "    for feature in num_feature_list:\n",
    "        tmp = data.groupby(group)[feature].agg([sum, min, max, np.mean]).reset_index()\n",
    "        tmp = pd.merge(data, tmp, on=group, how='left')\n",
    "        data['{}-mean_gb_{}'.format(feature, group)] = data[feature] - tmp['mean']\n",
    "        data['{}-min_gb_{}'.format(feature, group)] = data[feature] - tmp['min']\n",
    "        data['{}-max_gb_{}'.format(feature, group)] = data[feature] - tmp['max']\n",
    "        data['{}/sum_gb_{}'.format(feature, group)] = data[feature] / tmp['sum']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = data[~data['label'].isna()], data[data['label'].isna()]\n",
    "y = X_train['label']\n",
    "drop_features = ['label', 'id', 'CSNY']\n",
    "\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_test = X_test.drop(drop_features, axis=1)\n",
    "\n",
    "cat_col = ['HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU', 'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT']\n",
    "X_train[cat_col] = X_train[cat_col].astype('category')\n",
    "X_test[cat_col] = X_test[cat_col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "trn_idx: [ 3984  3985  3986 ... 39997 39998 39999]\n",
      "val_idx: [   0    1    2 ... 4156 4170 4172]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's auc: 0.996878\tvalid_1's auc: 0.939339\n",
      "fold n°1\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [3984 3985 3986 ... 8228 8249 8282]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's auc: 0.998652\tvalid_1's auc: 0.944276\n",
      "fold n°2\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [ 7985  7986  7987 ... 12133 12135 12150]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's auc: 0.988153\tvalid_1's auc: 0.944468\n",
      "fold n°3\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [11987 11988 11989 ... 15998 15999 16000]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 0.999999\tvalid_1's auc: 0.92435\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's auc: 0.999985\tvalid_1's auc: 0.925047\n",
      "fold n°4\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [15982 16001 16002 ... 20317 20343 20364]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\ttraining's auc: 0.996352\tvalid_1's auc: 0.929188\n",
      "fold n°5\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [19975 19976 19977 ... 24382 24393 24455]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's auc: 0.999397\tvalid_1's auc: 0.915852\n",
      "fold n°6\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [23964 23965 23966 ... 28256 28275 28288]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's auc: 0.999229\tvalid_1's auc: 0.929216\n",
      "fold n°7\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [27971 27972 27973 ... 32011 32014 32019]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's auc: 0.999359\tvalid_1's auc: 0.920844\n",
      "fold n°8\n",
      "trn_idx: [    0     1     2 ... 39997 39998 39999]\n",
      "val_idx: [31996 31997 31998 ... 36100 36108 36124]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's auc: 0.989665\tvalid_1's auc: 0.91782\n",
      "fold n°9\n",
      "trn_idx: [    0     1     2 ... 36100 36108 36124]\n",
      "val_idx: [35995 35996 35997 ... 39997 39998 39999]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 1\tvalid_1's auc: 0.933527\n",
      "Early stopping, best iteration is:\n",
      "[334]\ttraining's auc: 0.999906\tvalid_1's auc: 0.934062\n",
      "AUC score: 0.9281340242753356\n",
      "TPR weight: 0.4726151614073268\n"
     ]
    }
   ],
   "source": [
    "# 训练&预测\n",
    "KF = StratifiedKFold(n_splits=10, random_state=2000)\n",
    "params = {\n",
    "    'verbose':-1, \n",
    "    'objective':'binary',\n",
    "    'metric':'auc',\n",
    "    'num_iterations': 10000, \n",
    "}\n",
    "\n",
    "\n",
    "oof_lgb = np.zeros(len(X_train))\n",
    "predictions_lgb = np.zeros((len(X_test)))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(X_train.values, y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print('trn_idx:',trn_idx)\n",
    "    print('val_idx:',val_idx)\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx],label=y.iloc[trn_idx])    \n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx],label=y.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(\n",
    "        params,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds=200,  \n",
    "        categorical_feature=cat_col\n",
    "    )\n",
    "        \n",
    "    oof_lgb[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    predictions_lgb[:] += clf.predict(X_test, num_iteration=clf.best_iteration) \n",
    "print(\"AUC score: {}\".format(roc_auc_score(y, oof_lgb)))\n",
    "print(\"TPR weight: {}\".format(tpr_weight_funtion(y, oof_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('submit.csv')\n",
    "submit['label'] = predictions_lgb / 5\n",
    "submit.to_csv('submit_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
